% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Bootstrap \& MCMC Tutorial},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Bootstrap \& MCMC Tutorial}
\author{}
\date{\vspace{-2.5em}2024-06-12}

\begin{document}
\maketitle

\hypertarget{background}{%
\section{Background}\label{background}}

\hypertarget{randomization-techniques-why-do-we-use-them}{%
\subsection{Randomization techniques: why do we use
them?}\label{randomization-techniques-why-do-we-use-them}}

Data resampling and randomization methods are most often used for 1)
Evaluating uncertainty levels in data 2) Hypothesis testing 3) Improving
model fit/performance

Common methods include \emph{\textbf{Bootstrapping}: ``pulling yourself
up by your bootstraps''; pulling random samples from your data to
\emph{evaluate} the distribution of metrics of interest and obtain
\emph{confidence intervals} for computed statistics
}\_\_Permutations\_\_: randomizing your data by keeping some parameters
constant and varying others, then comparing to a null distribution to
ask if your data structure differs significantly from the null
expectation; i.e., \emph{hypothesis testing} *\textbf{Markov Chains}:
simulate different possible values of model parameters through random
sampling, incorporating fixed and random effects; can \emph{improve
model performance} when chains are mixed well. This method is based on
Bayesian inference, but for the way we will use it in this tutorial, it
basically is just a juiced-up generalized linear mixed effects model
(GLMM).

\hypertarget{tutorial}{%
\section{Tutorial}\label{tutorial}}

\hypertarget{example-dataset}{%
\subsection{Example dataset}\label{example-dataset}}

The dataset we will use for the tutorial shows feeder visitations by
birds in mixed-species flocks in Lincoln, Nebraska. This a summarized
version of that dataset which aggregates each individual's number of
morning visitations (sumvisits) and compares them to the lowest
temperature from the previous night. If you would like to learn more
about the original study, you can find it here
\url{https://academic.oup.com/beheco/article/32/3/407/6163219} and the
full dataset and code for its analysis can be found here
\url{https://datadryad.org/stash/dataset/doi:10.5061/dryad.x69p8czgr}

The original study used a Markov Chain Monte Carlo model to test the
effects of overnight temperature on morning feeder visitation by birds
in mixed-species flocks. Here, we will be adding a component not used in
the original study to demonstrate bootstrapping. The original study also
used permutations to test if pairs of birds with a strong social
connection had similar foraging activity. We will start the tutorial
with bootstrapping, then move to Markov Chains, and finally end with
permutation.

\hypertarget{bootstrapping}{%
\subsection{Bootstrapping}\label{bootstrapping}}

\hypertarget{data-visualization-and-exploration}{%
\subsubsection{Data visualization and
exploration}\label{data-visualization-and-exploration}}

First, we need to load the visitation data and investigate the variables
of interest, ``sumvisits'' (feeder visitation) and ``nightlows'' (the
lowest overnight temperature)

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{load}\NormalTok{(}\StringTok{"morn\_visits.dat"}\NormalTok{)}

\DocumentationTok{\#\# check out data structure}
\FunctionTok{head}\NormalTok{(morn\_visits)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         Date       RFID Species Sex sumvisits  nightlows
## 1 2019-01-27 011016B9B5    WBNU   M        11  -6.722222
## 2 2019-01-29 011016B9B5    WBNU   M         1 -18.888889
## 3 2019-01-30 011016B9B5    WBNU   M        21 -22.222222
## 4 2019-01-31 011016B9B5    WBNU   M        14 -17.777778
## 5 2019-02-01 011016B9B5    WBNU   M        13 -11.722222
## 6 2019-02-02 011016B9B5    WBNU   M         2   1.111111
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Let\textquotesingle{}s look at the distributions of our variables of interest}
\FunctionTok{hist}\NormalTok{(morn\_visits}\SpecialCharTok{$}\NormalTok{sumvisits) }\DocumentationTok{\#\# left{-}biased distribution, aka Poisson}
\end{Highlighting}
\end{Shaded}

\includegraphics{Tutorial_Resources_files/figure-latex/unnamed-chunk-1-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(morn\_visits}\SpecialCharTok{$}\NormalTok{sumvisits)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 33.39792
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{hist}\NormalTok{(morn\_visits}\SpecialCharTok{$}\NormalTok{nightlows) }\DocumentationTok{\#\# fairly Gaussian, but not perfect, may need to rescale if model fit is off}
\end{Highlighting}
\end{Shaded}

\includegraphics{Tutorial_Resources_files/figure-latex/unnamed-chunk-1-2.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(morn\_visits}\SpecialCharTok{$}\NormalTok{nightlows)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -12.90478
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{hist}\NormalTok{(morn\_visits}\SpecialCharTok{$}\NormalTok{Date, }\AttributeTok{breaks =} \StringTok{"day"}\NormalTok{) }\DocumentationTok{\#\# data distribution over the study is fairly even, except for a gap when there were technological issues with the RFID feeders}
\end{Highlighting}
\end{Shaded}

\includegraphics{Tutorial_Resources_files/figure-latex/unnamed-chunk-1-3.pdf}
\#\#\# Simple model Now that we know our data a little better, let's
start by running a simple generalized linear model to test the effects
of overnight temperature on feeder visitation.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{glm}\FloatTok{.1} \OtherTok{=} \FunctionTok{glm}\NormalTok{(}\AttributeTok{formula =}\NormalTok{ sumvisits }\SpecialCharTok{\textasciitilde{}}\NormalTok{ nightlows, }\AttributeTok{data =}\NormalTok{ morn\_visits, }\AttributeTok{family =} \StringTok{"poisson"}\NormalTok{)}
\FunctionTok{summary}\NormalTok{(glm}\FloatTok{.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = sumvisits ~ nightlows, family = "poisson", data = morn_visits)
## 
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)    
## (Intercept)  3.32029    0.01644  202.01   <2e-16 ***
## nightlows   -0.01434    0.00114  -12.58   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 16371  on 768  degrees of freedom
## Residual deviance: 16211  on 767  degrees of freedom
## AIC: 20001
## 
## Number of Fisher Scoring iterations: 5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Predictive graph for Temperature}
\NormalTok{temp }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{nightlows =} \FunctionTok{seq}\NormalTok{(}\FunctionTok{min}\NormalTok{(morn\_visits}\SpecialCharTok{$}\NormalTok{nightlows),}\FunctionTok{max}\NormalTok{(morn\_visits}\SpecialCharTok{$}\NormalTok{nightlows)), }\AttributeTok{by =} \FloatTok{0.5}\NormalTok{, }\AttributeTok{Date =} \FunctionTok{median}\NormalTok{(morn\_visits}\SpecialCharTok{$}\NormalTok{Date), }\AttributeTok{RFID =} \FunctionTok{sample}\NormalTok{(morn\_visits}\SpecialCharTok{$}\NormalTok{RFID,}\DecValTok{1}\NormalTok{), }\AttributeTok{Species =} \StringTok{"DOWO"}\NormalTok{, }\AttributeTok{Sex =} \StringTok{"M"}\NormalTok{)}
\NormalTok{temp}\SpecialCharTok{$}\NormalTok{Predict }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(glm}\FloatTok{.1}\NormalTok{, temp, }\AttributeTok{type =} \StringTok{"response"}\NormalTok{) }\CommentTok{\# takes parameters from model and returns values for the response variable}
\FunctionTok{plot}\NormalTok{(temp}\SpecialCharTok{$}\NormalTok{nightlows, temp}\SpecialCharTok{$}\NormalTok{Predict, }\AttributeTok{xlab =} \StringTok{"Nightly Temperature"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Number of Visits"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Tutorial_Resources_files/figure-latex/unnamed-chunk-2-1.pdf}

Let's look at the residuals to assess model fit. The fitted vs.~residual
plot should have no clear trend and there should be a normal
distribution of the residuals.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modres }\OtherTok{=} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{x =} \FunctionTok{na.omit}\NormalTok{(}\FunctionTok{fitted}\NormalTok{(glm}\FloatTok{.1}\NormalTok{)), }\AttributeTok{y =} \FunctionTok{na.omit}\NormalTok{(}\FunctionTok{resid}\NormalTok{(glm}\FloatTok{.1}\NormalTok{)))}
\FunctionTok{plot}\NormalTok{(modres}\SpecialCharTok{$}\NormalTok{x, modres}\SpecialCharTok{$}\NormalTok{y,}
     \AttributeTok{ylab =} \StringTok{"Residuals"}\NormalTok{, }\AttributeTok{xlab =} \StringTok{"Fitted values (visits)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Tutorial_Resources_files/figure-latex/unnamed-chunk-3-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{hist}\NormalTok{(modres}\SpecialCharTok{$}\NormalTok{y) }
\end{Highlighting}
\end{Shaded}

\includegraphics{Tutorial_Resources_files/figure-latex/unnamed-chunk-3-2.pdf}

Let's look at the quantiles to assess model fit. The theoretical and
sample quantiles should fall along the normal quantiles line.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{qqnorm}\NormalTok{(morn\_visits}\SpecialCharTok{$}\NormalTok{sumvisits) }
\FunctionTok{qqline}\NormalTok{(morn\_visits}\SpecialCharTok{$}\NormalTok{sumvisits)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Tutorial_Resources_files/figure-latex/unnamed-chunk-4-1.pdf}
Hm, it's not a perfect model fit. The residuals aren't quite a normal
distribution and our Q-Q plot is not quite a straight line. Maybe the
model assumptions aren't met or the distribution is thrown off by
something. Let's see if we can improve model fit.

\hypertarget{bootstrap-a-simple-statistic}{%
\subsubsection{Bootstrap a simple
statistic}\label{bootstrap-a-simple-statistic}}

First, to demonstrate the logic behind bootstrapping, let's bootstrap a
simple statistic to evaluate our distributions and accuracy. To do this
we are going to build a simple function to resample the data and
calculate a bootstrap statistic.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bootstrap }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(data, samp\_size, calc\_statistic, b\_iter) \{}
\NormalTok{  boot\_statistic }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{() \{}
\NormalTok{    boot\_sample }\OtherTok{=} \FunctionTok{sample}\NormalTok{(}\AttributeTok{x =}\NormalTok{ data, }\AttributeTok{size =}\NormalTok{ samp\_size, }\AttributeTok{replace =}\NormalTok{ T) }\DocumentationTok{\#\# randomly sample rows with replacement; enter sample values as samp\_size, up to the original sample size}
    \FunctionTok{calc\_statistic}\NormalTok{(boot\_sample) }\DocumentationTok{\#\# apply the statistic of interest}
\NormalTok{  \}}
  
  \FunctionTok{replicate}\NormalTok{(}\AttributeTok{n =}\NormalTok{ b\_iter, }\AttributeTok{expr =} \FunctionTok{boot\_statistic}\NormalTok{())  }\DocumentationTok{\#\# perform the bootstrap multiple times by changing b\_iter}
\NormalTok{\}}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{457}\NormalTok{)}
\NormalTok{sdvals }\OtherTok{=} \FunctionTok{bootstrap}\NormalTok{(}\AttributeTok{data=}\NormalTok{morn\_visits}\SpecialCharTok{$}\NormalTok{nightlows, }\AttributeTok{samp\_size=}\FunctionTok{nrow}\NormalTok{(morn\_visits), }\AttributeTok{calc\_statistic=}\NormalTok{sd, }\AttributeTok{b\_iter=}\DecValTok{1000}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Now look at the distribution of values

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{hist}\NormalTok{(sdvals)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Tutorial_Resources_files/figure-latex/unnamed-chunk-6-1.pdf}
Calculate the 95\% confidence intervals

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{quantile}\NormalTok{(sdvals, }\AttributeTok{probs =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.025}\NormalTok{,}\FloatTok{0.975}\NormalTok{)) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     2.5%    97.5% 
## 5.275811 5.780584
\end{verbatim}

This example should help you understand some of the logic behind
bootstrapping. However, you don't have to write your own function for
everything--there are also premade packages in R for bootstrapping,
including the \emph{mosaic} package (see here for a specific tutorial on
\emph{mosaic} \url{https://rpubs.com/robbsinn/s11}) and the \emph{boot}
package \url{https://www.mayin.org/ajayshah/KB/R/documents/boot.html}.
These use wrappers to apply different statistics to your data. They also
have a wider variety of options to fine-tune your resampling methods for
simple statistics.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(boot)}
\NormalTok{??boot}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## starting httpd help server ... done
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(mosaic)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: package 'mosaic' was built under R version 4.3.3
\end{verbatim}

\begin{verbatim}
## Registered S3 method overwritten by 'mosaic':
##   method                           from   
##   fortify.SpatialPolygonsDataFrame ggplot2
## 
## The 'mosaic' package masks several functions from core packages in order to add 
## additional features.  The original behavior of these functions should not be affected by this.
## 
## Attaching package: 'mosaic'
## 
## The following objects are masked from 'package:dplyr':
## 
##     count, do, tally
## 
## The following object is masked from 'package:Matrix':
## 
##     mean
## 
## The following object is masked from 'package:ggplot2':
## 
##     stat
## 
## The following object is masked from 'package:boot':
## 
##     logit
## 
## The following objects are masked from 'package:stats':
## 
##     binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,
##     quantile, sd, t.test, var
## 
## The following objects are masked from 'package:base':
## 
##     max, mean, min, prod, range, sample, sum
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{??mosaic}
\end{Highlighting}
\end{Shaded}

\hypertarget{bootstrap-model-outputs}{%
\subsubsection{Bootstrap model outputs}\label{bootstrap-model-outputs}}

Now let's apply the same logic to the GLM to get a bootstrapped model
parameter and calculate confidence intervals. We will do this for our
response estimate. Basically, we will run the model a bunch of times,
resampling the data each time and grabbing our parameter of interest.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## -- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --
## v forcats   1.0.0     v stringr   1.5.0
## v lubridate 1.9.2     v tibble    3.2.1
## v purrr     1.0.1     v tidyr     1.3.0
## v readr     2.1.4     
## -- Conflicts ------------------------------------------ tidyverse_conflicts() --
## x mosaic::count() masks dplyr::count()
## x purrr::cross()  masks mosaic::cross()
## x mosaic::do()    masks dplyr::do()
## x tidyr::expand() masks Matrix::expand()
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()
## x tidyr::pack()   masks Matrix::pack()
## x mosaic::stat()  masks ggplot2::stat()
## x mosaic::tally() masks dplyr::tally()
## x tidyr::unpack() masks Matrix::unpack()
## i Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{glmdf }\OtherTok{=} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Estimate =} \FunctionTok{numeric}\NormalTok{()) }\DocumentationTok{\#\#initialize dataframe for our output parameters}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{1000}\NormalTok{)\{}
\NormalTok{  sampdata }\OtherTok{=} \FunctionTok{sample\_n}\NormalTok{(morn\_visits, }\AttributeTok{size =} \FunctionTok{nrow}\NormalTok{(morn\_visits), }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{) }\DocumentationTok{\#\# randomly sample rows with replacement up to the original sample size}
\NormalTok{  glm\_temp }\OtherTok{=} \FunctionTok{glm}\NormalTok{(}\AttributeTok{formula =}\NormalTok{ sumvisits }\SpecialCharTok{\textasciitilde{}}\NormalTok{ nightlows, }\AttributeTok{data =}\NormalTok{ sampdata, }\AttributeTok{family =} \StringTok{"poisson"}\NormalTok{) }\DocumentationTok{\#\# model the effects of interest}
\NormalTok{  glmdf }\OtherTok{=} \FunctionTok{rbind}\NormalTok{(glmdf, }\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Estimate =} \FunctionTok{summary}\NormalTok{(glm\_temp)}\SpecialCharTok{$}\NormalTok{coefficients[, }\DecValTok{1}\NormalTok{][}\DecValTok{2}\NormalTok{])) }\DocumentationTok{\#\# save the output to our dataframe}
\NormalTok{\}}

\FunctionTok{quantile}\NormalTok{(glmdf}\SpecialCharTok{$}\NormalTok{Estimate,}\AttributeTok{probs =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.025}\NormalTok{,}\FloatTok{0.975}\NormalTok{)) }\DocumentationTok{\#\# get confidence intervals; cool, they do not overlap with zero! That would mean we cannot reject the null hypothesis{-}{-}i.e., that there is no relationship between the response and predictor variables}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         2.5%        97.5% 
## -0.025744856 -0.003013217
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{hist}\NormalTok{(glmdf}\SpecialCharTok{$}\NormalTok{Estimate) }\DocumentationTok{\#\# look at the distribution of the parameter}
\end{Highlighting}
\end{Shaded}

\includegraphics{Tutorial_Resources_files/figure-latex/unnamed-chunk-9-1.pdf}

\hypertarget{markov-chain-monte-carlo-mcmc-glmm}{%
\subsection{Markov Chain Monte Carlo (MCMC)
GLMM}\label{markov-chain-monte-carlo-mcmc-glmm}}

Now let's try a different randomization method that also incorporates
more complexity from our data. We initially built a simple model with
only a response and a single predictor. But in this dataset, we also
know there are individuals that may differ in their behavior and we
might expect that behavior differs by day, depending on flockmates and
other factors. We can incorporate that complexity into the model and
into the randomization process itself with MCMC.

Let's run through the logic for MCMC before we continue. These models
are complex, and the function we will use ``black-boxes'' the methods.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(MCMCglmm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: package 'MCMCglmm' was built under R version 4.3.2
\end{verbatim}

\begin{verbatim}
## Loading required package: coda
\end{verbatim}

\begin{verbatim}
## Warning: package 'coda' was built under R version 4.3.2
\end{verbatim}

\begin{verbatim}
## Loading required package: ape
\end{verbatim}

\begin{verbatim}
## 
## Attaching package: 'ape'
\end{verbatim}

\begin{verbatim}
## The following object is masked from 'package:dplyr':
## 
##     where
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{??MCMCglmm}
\end{Highlighting}
\end{Shaded}

The way that MCMC randomizes data is actually by simulating a new data
``chain'' using a probability of moving from one point to another. As
the data is simulated, we might find that data points simulated one
after the other are dependent on the previous point. This is important
to know because one of the assumptions of a linear model is that data
points are independent of each other. To account for this, we can
discard every nth data point to maintain independence. We can adjust
this with the ``thin'' argument.

It's also possible that when the chain starts, its first set of
simulated data points are less random than as the simulation continues.
We may then want to discard osbervations from the beginning of the
chain. We can adjust this using the ``burnin'' argument.

One great thing about the MCMCMglmm package is that it has nifty
built-in functions to run diagnostic tests to find the best parameters
for the model. We can find the optimum burn-in period, sample size
(total), and dependence factor (nth step without losing important info).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{raftery.diag}\NormalTok{(morn\_visits}\SpecialCharTok{$}\NormalTok{sumvisits, }\AttributeTok{q =} \FloatTok{0.05}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Quantile (q) = 0.05
## Accuracy (r) = +/- 0.005
## Probability (s) = 0.95 
## 
## You need a sample size of at least 7299 with these values of q, r and s
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{glmm}\FloatTok{.1} \OtherTok{\textless{}{-}} \FunctionTok{MCMCglmm}\NormalTok{(}\AttributeTok{fixed =}\NormalTok{ sumvisits}\SpecialCharTok{\textasciitilde{}}\NormalTok{nightlows,}
                   \AttributeTok{random =} \SpecialCharTok{\textasciitilde{}}\NormalTok{RFID}\SpecialCharTok{+}\NormalTok{Date,}
                   \AttributeTok{family =} \StringTok{"poisson"}\NormalTok{,}
                   \AttributeTok{data =}\NormalTok{ morn\_visits, }
                   \AttributeTok{nitt =} \DecValTok{7400}\NormalTok{,}
                   \AttributeTok{burnin =} \DecValTok{100}\NormalTok{,}
                   \AttributeTok{thin =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: Unknown or uninitialised column: `family`.
\end{verbatim}

\begin{verbatim}
## 
##                        MCMC iteration = 0
## 
##  Acceptance ratio for liability set 1 = 0.000315
## 
##                        MCMC iteration = 1000
## 
##  Acceptance ratio for liability set 1 = 0.397322
## 
##                        MCMC iteration = 2000
## 
##  Acceptance ratio for liability set 1 = 0.400381
## 
##                        MCMC iteration = 3000
## 
##  Acceptance ratio for liability set 1 = 0.401224
## 
##                        MCMC iteration = 4000
## 
##  Acceptance ratio for liability set 1 = 0.400049
## 
##                        MCMC iteration = 5000
## 
##  Acceptance ratio for liability set 1 = 0.399919
## 
##                        MCMC iteration = 6000
## 
##  Acceptance ratio for liability set 1 = 0.399849
## 
##                        MCMC iteration = 7000
## 
##  Acceptance ratio for liability set 1 = 0.400805
\end{verbatim}

Let's look at the residuals. Again, there should be no clear trends--the
messier, the better.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(glmm}\FloatTok{.1}\SpecialCharTok{$}\NormalTok{Sol)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Tutorial_Resources_files/figure-latex/unnamed-chunk-12-1.pdf}
These look pretty good. We can also check overdispersed points to see if
there is overlap; this estimates how much between-chain variance could
be reduced if the chains were run longer.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{autocorr}\NormalTok{(glmm}\FloatTok{.1}\SpecialCharTok{$}\NormalTok{Sol)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## , , (Intercept)
## 
##         (Intercept)     nightlows
## Lag 0   1.000000000  0.6843990990
## Lag 1   0.008967196  0.0114472219
## Lag 5   0.006243232 -0.0002864469
## Lag 10 -0.019514316 -0.0056234806
## Lag 50 -0.016862066 -0.0234951404
## 
## , , nightlows
## 
##          (Intercept)    nightlows
## Lag 0   0.6843990990  1.000000000
## Lag 1   0.0110591045  0.015821868
## Lag 5   0.0156491389  0.011861528
## Lag 10 -0.0083865158  0.008530944
## Lag 50  0.0005504137 -0.004213824
\end{verbatim}

There is very low autocorrelation between points, so that is good.

We can also check model performance by running multiple chains and
making sure they are all well mixed. We will use parallel processing to
make this part go faster.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(doParallel)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Loading required package: foreach
\end{verbatim}

\begin{verbatim}
## 
## Attaching package: 'foreach'
\end{verbatim}

\begin{verbatim}
## The following objects are masked from 'package:purrr':
## 
##     accumulate, when
\end{verbatim}

\begin{verbatim}
## Loading required package: iterators
\end{verbatim}

\begin{verbatim}
## Loading required package: parallel
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(foreach)}
\CommentTok{\# Initialize parallel backend}
\FunctionTok{registerDoParallel}\NormalTok{(}\AttributeTok{cores =} \DecValTok{4}\NormalTok{)}
\CommentTok{\# Use foreach to parallelize the loop}
\FunctionTok{timestamp}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## ##------ Fri Jun 21 15:56:05 2024 ------##
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{glmm.mult }\OtherTok{\textless{}{-}} \FunctionTok{foreach}\NormalTok{(}\AttributeTok{i =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{4}\NormalTok{, }\AttributeTok{.packages =} \StringTok{\textquotesingle{}MCMCglmm\textquotesingle{}}\NormalTok{) }\SpecialCharTok{\%dopar\%}\NormalTok{ \{}
    \FunctionTok{MCMCglmm}\NormalTok{(}\AttributeTok{fixed =}\NormalTok{ sumvisits}\SpecialCharTok{\textasciitilde{}}\NormalTok{nightlows,}
             \AttributeTok{random =} \SpecialCharTok{\textasciitilde{}}\NormalTok{RFID}\SpecialCharTok{+}\NormalTok{Date,}
             \AttributeTok{family =} \StringTok{"poisson"}\NormalTok{,}
             \AttributeTok{data =}\NormalTok{ morn\_visits, }
             \AttributeTok{nitt =} \DecValTok{7300}\NormalTok{, }
             \AttributeTok{burnin =} \DecValTok{8}\NormalTok{)}
\NormalTok{\}}
\FunctionTok{timestamp}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## ##------ Fri Jun 21 15:56:11 2024 ------##
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Stop parallel backend{-}{-} DON\textquotesingle{}T FORGET TO DO THIS!}
\FunctionTok{stopImplicitCluster}\NormalTok{()}

\NormalTok{glmm.mult}\FloatTok{.1} \OtherTok{\textless{}{-}} \FunctionTok{lapply}\NormalTok{(glmm.mult, }\ControlFlowTok{function}\NormalTok{(m) m}\SpecialCharTok{$}\NormalTok{Sol)}
\NormalTok{glmm.mult}\FloatTok{.1} \OtherTok{\textless{}{-}} \FunctionTok{do.call}\NormalTok{(mcmc.list, glmm.mult}\FloatTok{.1}\NormalTok{)}
\DocumentationTok{\#\# Potential scale reduction factors (PSRF) should be close to one, ideally \textless{} 1.2}
\FunctionTok{gelman.diag}\NormalTok{(glmm.mult}\FloatTok{.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Potential scale reduction factors:
## 
##             Point est. Upper C.I.
## (Intercept)          1          1
## nightlows            1          1
## 
## Multivariate psrf
## 
## 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(glmm.mult}\FloatTok{.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Tutorial_Resources_files/figure-latex/unnamed-chunk-14-1.pdf}
The basic procedure I described was adopted from ECOLOGICAL MODELS AND
DATA IN R: 7.3 - MARKOV CHAIN MONTE CARLO (PAGE 233). There are many
more details there. I also used a custom function from an intro to
MCMCglmm resource, which you should peruse to find more examples and
more detailed explanation:
\url{https://github.com/tmalsburg/MCMCglmm-intro}.

Another great resource for understanding these types of Bayesian models
is Richard McElreath's Statistical Rethinking course:
\url{https://github.com/rmcelreath/stat_rethinking_2023}.

\hypertarget{permutation}{%
\subsection{Permutation}\label{permutation}}

The permutation method

\end{document}
